[TOC]

# 神经网络

## 神经元模型

​		神经网络(neural networks)方面的研究很早就已出现，今天“神经网络”已是一个相当大的、多学科交叉的学科领域。各相关学科对神经网络的定义多种多样，本书采用目前使用得最广泛的一种，即“神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应”。我们在机器学习中谈论神经网络时指的是“神经网络学习”，或者说，是机器学习与神经网络这两个学科领域的交叉部分。

​		神经网络中最基本的成分是神经元(neuron)模型，即上述定义中的“简单单元”。在生物神经网络中，每个神经元与其他神经元相连，当它的电位超过了一个“阈值”(threshold)，那么它就会被激活，即“兴奋”起来，然后向相连的神经元发送化学物质，从而改变这些神经元内的电位。

​		将上述情形抽象为下图所示的简单模型，这就是一直沿用至今的“M-P神经元模型”。在这个模型中，神经元接收到来自 n 个其他神经元传递过来的输入信号，这些输入信号通过带权重的连接(connection)进行传递，神经元接收到的总输入值将与神经元的阈值进行比较，然后通过“激活函数”(activation function)处理以产生神经元的输出。

![M-P神经元模型.png](https://github.com/Giyn/QG2020SummerTraining/blob/master/Pictures/BPNN/M-P%E7%A5%9E%E7%BB%8F%E5%85%83%E6%A8%A1%E5%9E%8B.png?raw=true)

​		理想中的激活函数是下图(a)所示的阶跃函数，它将输入值映射为输出值“0”或“1”，显然“1”对应于神经元兴奋，“0”对应于神经元抑制。然而，阶跃函数具有不连续、不光滑等不太好的性质，因此实际常用 Sigmoid 函数作为激活函数。典型的 Sigmoid 函数如下图(b)所示，它把可能在较大范围内变化的输入值挤压到 (0,1) 输出值范围内，因此有时也称为“挤压函数”(squashing function)。

![典型的神经元激活函数.png](https://github.com/Giyn/QG2020SummerTraining/blob/master/Pictures/BPNN/%E5%85%B8%E5%9E%8B%E7%9A%84%E7%A5%9E%E7%BB%8F%E5%85%83%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.png?raw=true)

​		把许多个这样的神经元按一定的层次结构连接起来，就得到了神经网络。
​		事实上，从计算机科学的角度看，我们可以先不考虑神经网络是否真的模拟了生物神经网络，只需将一个神经网络视为包含了许多参数的数学模型，这个模型是若干个函数，例如 $y_j=f(\sum_iw_ix_i-\theta_j)$ 相互(嵌套)代入而得。有效的神经网络学习算法大多以数学证明为支撑。

>例如 10 个神经元两两连接，则有 100 个参数：90 个连接权和 10 个阈值。



## 感知机与多层网络

​		感知机(Perceptron)由两层神经元组成，如下图所示，输入层接收外界输入信号后传递给输出层，输出层是 M-P 神经元，亦称“阈值逻辑单元”(threshold logic unit)。

![两个输入神经元的感知机网络结构示意图.png](https://github.com/Giyn/QG2020SummerTraining/blob/master/Pictures/BPNN/%E4%B8%A4%E4%B8%AA%E8%BE%93%E5%85%A5%E7%A5%9E%E7%BB%8F%E5%85%83%E7%9A%84%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E7%A4%BA%E6%84%8F%E5%9B%BE.png?raw=true)

​		感知机能容易地实现逻辑与、或、非运算。注意到 $y=f(\sum_iw_ix_i-\theta)$，假定 $f$ 是上图中的阶跃函数，有

- “与” $(x_1\and x_2)$：令 $w_1=w_2=1,\theta=2$，则 $y=f(1·x_1+1·x_2-2)$，仅在 $x_1=x_2=1$ 时，$y=1$；

- “或” $(x_1\or x_2)$：令 $w_1=w_2=1,\theta=0.5$，则 $y=f(1·x_1+1·x_2-0.5)$，当 $x_1=1$ 或 $x_2=1$ 时，$y=1$；

- “非” $(\neg x_1)$：令 $w_1=-0.6$，$w_2=0$，$\theta=-0.5$，则 $y=f(-0.6·x_1+0·x_2+0.5)$，当 $x_1=1$ 时，$y=0$；当 $x_1=0$ 时，$y=1$。



​		更一般地，给定训练数据集，权重 $w_i(i=1,2,...,n)$ 以及阈值 $θ$ 可通过学习得到。阈值 $θ$ 可看作一个固定输入为 $-1.0$ 的“哑结点”(dummy node)所对应的连接权重 $w_{n+1}$，这样，权重和阈值的学习就可统一为权重的学习。感知机学习规则非常简单，对训练样例 $(x, y)$，若当前感知机的输出为 $\hat{y}$，则感知机权重将这样调整：
$$
w_i\leftarrow w_i+	\Delta w_i\,\,,\tag{1}
$$

$$
\Delta w_i=\eta(y-\hat{y})x_i\,\,,\tag{2}
$$

其中 $η∈(0, 1)$ 称为学习率(learning rate)。从式 (1) 可看出，若感知机对训练样例 $(x,y)$ 预测正确，即 $\hat{y}=y$，则感知机不发生变化，否则将根据错误的程度进行权重调整。

>$η$ 通常设置为一个小正数，例如0.1。

​	

​		需注意的是，感知机只有输出层神经元进行激活函数处理，即只拥有一层功能神经元(functional neuron)，其学习能力非常有限。事实上，上述与、或、非问题都是线性可分(linearly separable)的问题。可以证明，若两类模式是线性可分的，即存在一个线性超平面能将它们分开，如下图 (a)-(c) 所示，则感知机的学习过程一定会收敛(converge)而求得适当的权向量 $w = (w_1; w_2;...;w_{n+1})$；否则感知机学习过程将会发生振荡(fuctuation)，$w$ 难以稳定下来，不能求得合适解，例如感知机甚至不能解决如下图 (d) 所示的异或这样简单的非线性可分问题。

![线性可分的“与”“或”“非”问题与非线性可分的“异或”问题.png](https://github.com/Giyn/QG2020SummerTraining/blob/master/Pictures/BPNN/%E7%BA%BF%E6%80%A7%E5%8F%AF%E5%88%86%E7%9A%84%E2%80%9C%E4%B8%8E%E2%80%9D%E2%80%9C%E6%88%96%E2%80%9D%E2%80%9C%E9%9D%9E%E2%80%9D%E9%97%AE%E9%A2%98%E4%B8%8E%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%8F%AF%E5%88%86%E7%9A%84%E2%80%9C%E5%BC%82%E6%88%96%E2%80%9D%E9%97%AE%E9%A2%98.png?raw=true)

​		要解决非线性可分问题，需考虑使用多层功能神经元。例如下图中这个简单的两层感知机就能解决异或问题。在下图 (a) 中，输出层与输入层之间的一层神经元，被称为隐层或隐含层(hiddenlayer)，隐含层和输出层神经元都是拥有激活函数的功能神经元。

![能解决异或问题的两层感知机.png](https://github.com/Giyn/QG2020SummerTraining/blob/master/Pictures/BPNN/%E8%83%BD%E8%A7%A3%E5%86%B3%E5%BC%82%E6%88%96%E9%97%AE%E9%A2%98%E7%9A%84%E4%B8%A4%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA.png?raw=true)

​	更一般的，常见的神经网络是形如下图所示的层级结构，每层神经元与下一层神经元全互连，神经元之间不存在同层连接，也不存在跨层连接。这样的神经网络结构通常称为“多层前馈神经网络”(multi-layer feedforward neural networks)，其中输入层神经元接收外界输入，隐层与输出层神经元对信号进行加工，最终结果由输出层神经元输出；换言之，输入层神经元仅是接受输入，不进行函数处理，隐层与输出层包含功能神经元。因此，下图 (a) 通常被称为“两层网络”。为避免歧义，本书称其为“单隐层网络”。只需包含隐层，即可称为多层网络。神经网络的学习过程，就是根据训练数据来调整神经元之间的“连接权”(connection weight)以及每个功能神经元的阈值；换言之，神经网络“学”到的东西，蕴涵在连接权与阈值中。

![多层前馈神经网络结构示意图.png](https://github.com/Giyn/QG2020SummerTraining/blob/master/Pictures/BPNN/%E5%A4%9A%E5%B1%82%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E7%A4%BA%E6%84%8F%E5%9B%BE.png?raw=true)



## 误差逆传播算法（反向传播算法）

​		多层网络的学习能力比单层感知机强得多。欲训练多层网络，式 (1) 的简单感知机学习规则显然不够了，需要更强大的学习算法。误差逆传播(errorBackPropagation，简称 $BP$ )算法就是其中最杰出的代表，它是迄今最成功的神经网络学习算法。现实任务中使用神经网络时，大多是在使用 $BP$ 算法进行训练。值得指出的是，$BP$ 算法不仅可用于多层前馈神经网络，还可用于其他类型的神经网络，例如训练递归神经网络。但**通常说"$BP$ 网络”时，一般是指用 $BP$ 算法训练的多层前馈神经网络。**

​		下面我们来看看 $BP$ 算法究竟是什么样。给定训练集 $D=\{(x_1,y_1),(x_2, y_2),...,(x_m,y_m)\},x_i∈\mathbb{R}^d,y_i∈\mathbb{R}^l$，即输入示例由 $d$ 个属性描述，输出 $l$ 维实值向量。为便于讨论，下图给出了一个拥有 $d$ 个输入神经元、$l$ 个输出神经元、$q$ 个隐层神经元的多层前馈网络结构，其中输出层第 $j$ 个神经元的阈值用 $\theta_j$ 表示，隐层第 $h$ 个神经元的阈值用 $γ_h$ 表示。输入层第 $i$ 个神经元与隐层第 $h$ 个神经元之间的连接权为 $v_{ih}$，隐层第 $h$ 个神经元与输出层第 $j$ 个神经元之间的连接权为 $w_{hj}$。记隐层第 $h$ 个神经元接收到的输入为 $\alpha_h=\sum^d_{i=1}v_{ih}x_i$，输出层第 $j$ 个神经元接收到的输入为 $\beta_h=\sum^q_{h=1}w_{hj}b_h$，其中 $b_h$ 为隐层第 $h$ 个神经元的输出。

![BP网络及算法中的变量符号.png](https://github.com/Giyn/QG2020SummerTraining/blob/master/Pictures/BPNN/BP%E7%BD%91%E7%BB%9C%E5%8F%8A%E7%AE%97%E6%B3%95%E4%B8%AD%E7%9A%84%E5%8F%98%E9%87%8F%E7%AC%A6%E5%8F%B7.png?raw=true)

>离散属性需先进行处理：若属性值间存在“序”关系则可进行连续化；否则通常转化为 $k$ 维向量，$k$ 为属性值数。

假设隐层和输出层神经元都使用 Sigmoid函数。对训练例 $(x_k,y_k)$，假定神经网络的输出为 $\hat{y}_k=(\hat{y}^k_1,\hat{y}^k_2,...,\hat{y}^k_l)$，即
$$
\hat{y}^k_j=f(\beta_j-\theta_j)\,\,,\tag{3}
$$
则网络在 $(x_k,y_k)$ 上的均方误差为
$$
E_k=\frac{1}{2}\sum_{j=1}^l(\hat{y}_j^k-y_j^k)^2\,\,.\tag{4}
$$

> 这里的 $\frac{1}{2}$ 是为了后续求导的便利。

​		上图的网络中有 $(d+l+1)q+l$ 个参数需确定：输入层到隐层的 $d×q$ 个权值、隐层到输出层的 $q×l$ 个权值、$q$ 个隐层神经元的阈值、$l$ 个输出层神经元的阈值。$BP$ 是一个迭代学习算法，在迭代的每一轮中采用广义的感知机学习规则对参数进行更新估计，即与式 (1) 类似，任意参数 $v$ 的更新估计式为
$$
v\leftarrow v+\Delta v\,\,.\tag{5}
$$
下面以上图中隐层到输出层的连接权 $w_{hj}$ 为例来进行推导。

​		$BP$ 算法基于梯度下降(gradient descent)策略，以目标的负梯度方向对参数进行调整。对式(4)的误差 $E_k$，给定学习率 $η$，有
$$
\Delta w_{hj}=-\eta\frac{\partial E_k}{\partial w_{hj}}\,\,.\tag{6}
$$
注意到 $w_{hj}$ 先影响到第 $j$ 个输出层神经元的输入值 $β_j$，再影响到其输出值 $\hat{y}^k_j$，然后影响到 $E_k$，有
$$
\frac{\partial E_k}{\partial w_{hj}}=\frac{\partial E_k}{\partial \hat{y}^k_j}·\frac{\partial \hat{y}_j^k}{\partial \beta_j}·\frac{\partial \beta_j}{\partial w_{hj}}\,\,.\tag{7}
$$

> 这就是“链式法则”。

​		根据 $\beta_j$ 的定义，显然有
$$
\frac{\partial\beta_j}{\partial w_{hj}}=b_h\,\,.\tag{8}
$$
​		Sigmoid 函数有一个很好的性质：
$$
f'(x)=f(x)(1-f(x))\,\,,\tag{9}
$$
于是根据式 (4) 和 (3)，有
$$
\begin{align}
g_j&=-\frac{\partial E_k}{\partial\hat{y}^k_j}·\frac{\partial\hat{y}_j^k}{\partial\beta_j}\\
&=-(\hat{y}^k_j-y^k_j)f'(\beta_j-\theta_j)\\
&=\hat{y}^k_j(1-\hat{y}_j^k)(y^k_j-\hat{y}_j^k)\,\,.\tag{10}
\end{align}
$$
​		将式 (10) 和 (8) 代入式 (7)，再代入式(6)，就得到了 $BP$ 算法中关于 $w_{hj}$ 的更新公式
$$
\Delta w_{hj}=\eta g_jb_h\,\,.\tag{11}
$$
​		类似可得
$$
\Delta \theta_j=-\eta g_j\,\,,\tag{12}
$$

$$
\Delta v_{ih}=\eta e_hx_i\,\,,\tag{13}
$$

$$
\Deltaγ_h=-\eta e_h\,\,,\tag{14}
$$

式 (13) 和 (14) 中
$$
\begin{align}
e_h&=-\frac{\partial E_k}{\partial b_h}·\frac{\partial b_h}{\partial \alpha_h}\\
&=-\sum^l_{j=1}\frac{\partial E_k}{\partial\beta_j}·\frac{\partial\beta_j}{\partial b_h}f'(\alpha_h-γ_h)\\
&=\sum^l_{j=1}w_{hj}g_jf'(\alpha_h-γ_h)\\
&=b_h(1-b_h)\sum^l_{j=1}w_{hj}g_j\,\,.\tag{15}
\end{align}
$$
​		学习率 $η∈(0,1)$ 控制着算法每一轮迭代中的更新步长，若太大则容易振荡，太小则收敛速度又会过慢。有时为了做精细调节，可令式 (11) 与 (12) 使用 $\eta_1$，式 (13) 与 (14) 使用 $η2$，两者未必相等。

> 常设置为 $η= 0.1$。

​		下图给出了 $BP$ 算法的工作流程。对每个训练样例，$BP$ 算法执行以下操作：先将输入示例提供给输入层神经元，然后逐层将信号前传，直到产生输出层的结果；然后计算输出层的误差(第 4-5 行)，再将误差逆向传播至隐层神经元(第 6 行)，最后根据隐层神经元的误差来对连接权和阈值进行调整(第 7 行)。该迭代过程循环进行，直到达到某些停止条件为止，例如训练误差已达到一个很小的值。

![误差逆传播算法.png](https://github.com/Giyn/QG2020SummerTraining/blob/master/Pictures/BPNN/%E8%AF%AF%E5%B7%AE%E9%80%86%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95.png?raw=true)

​		需注意的是，$BP$ 算法的目标是要最小化训练集 $D$ 上的累积误差
$$
E=\frac{1}{m}\sum^m_{k=1}E_k\,\,,\tag{16}
$$
​		但上面介绍的“标准 $BP$ 算法”每次仅针对一个训练样例更新连接权和阈值，也就是说，上图中算法的更新规则是基于单个的 $E_k$ 推导而得。如果类似地推导出基于累积误差最小化的更新规则，就得到了累积误差逆传播(accumulated error backpropagation)算法。

​		累积 $BP$ 算法与标准 $BP$ 算法都很常用。一般来说，标准 $BP$ 算法每次更新只针对单个样例，参数更新得非常频繁，而且对不同样例进行更新的效果可能出现“抵消”现象。因此，为了达到同样的累积误差极小点，标准 $BP$ 算法往往需进行更多次数的迭代。累积 $BP$ 算法直接针对累积误差最小化，它在读取整个训练集 $D$ 一遍后才对参数进行更新，其参数更新的频率低得多。

>读取训练集一遍称为进行了“一轮”(one round，亦称one epoch)学习。

​		但在很多任务中，累积误差下降到一定程度之后，进一步下降会非常缓慢，这时标准 $BP$ 往往会更快获得较好的解，尤其是在训练集 $D$ 非常大时更明显。

>标准 $BP$ 算法和累积 $BP$ 算法的区别类似于随机梯度下降(stochastic gradientdescent，简称SGD)与标准梯度下降之间的区别。

​		只需一个包含足够多神经元的隐层，多层前馈网络就能以任意精度逼近任意复杂度的连续函数。然而，如何设置隐层神经元的个数仍是个未决问题，实际应用中通常靠“试错法”(trial-by-error)调整。
​		正是由于其强大的表示能力，$BP$ 神经网络经常遭遇过拟合，其训练误差持续降低，但测试误差却可能上升。有两种策略常用来缓解 $BP$ 网络的过拟合。第一种策略是“早停”(early stopping)：将数据分成训练集和验证集，训练集用来计算梯度、更新连接权和阈值，验证集用来估计误差，若训练集误差降低但验证集误差升高，则停止训练，同时返回具有最小验证集误差的连接权和阈值。第二种策略是“正则化”(regularization)，其基本思想是在误差目标函数中增加一个用于描述网络复杂度的部分，例如连接权与阈值的平方和。仍令 $E_k$ 表示第 $k$ 个训练样例上的误差，$w_i$表示连接权和阈值，则误差目标函数 (16) 改变为
$$
E=\lambda\frac{1}{m}\sum^m_{k=1}E_k+(1-\lambda)\sum_{i}w_i^2\,\,,\tag{17}
$$

>增加连接权与阈值平方和这一项后，训练过程将会偏好比较小的连接权和阈值，使网络输出更加“光滑”，从而对过拟合有所缓解。

其中 $\lambda ∈(0,1)$ 用于对经验误差与网络复杂度这两项进行折中，常通过交叉验证法来估计。



## 全局最小与局部极小

​		若用 $E$ 表示神经网络在训练集上的误差，则它显然是关于连接权 $w$ 和阈值 $θ$ 的函数。此时，神经网络的训练过程可看作一个参数寻优过程，即在参数空间中，寻找一组最优参数使得 $E$ 最小。
​		我们常会谈到两种“最优”：“ 局部极小” (local minimum) 和“全局最小” (global minimum)。对 $w^*$ 和 $\theta^*$，若存在 $ε> 0$ 使得
$$
\forall(w;\theta)∈\{(w;\theta)\mid||(w;\theta)-(w^*;\theta^*)||\leq\epsilon\}\,\,,
$$
都有 $E(w;\theta)\geq E(w^*;\theta^*)$ 成立，则 $(w^*;\theta^*)$ 为局部极小解。若对参数空间中的任意 $(w;\theta)$ 都有 $E(w;\theta)\geq E(w^*;\theta^*)$，则 $(w^*;\theta^*)$ 为全局最小解。直观地看，局部极小解是参数空间中的某个点，其领域点的误差函数值均不小于该点的函数值;全局最小解则是指参数空间中所有点的误差函数值均不小于该点的误差函数值。两者对应的 $E(w^*;\theta^*)$ 分别称为误差函数的局部极小值和全局最小值。

​		显然，参数空间内梯度为零的点，只要其误差函数值小于邻点的误差函数值，就是局部极小点；可能存在多个局部极小值，但却只会有一个全局最小值。也就是说，“全局最小”一定是“局部极小”，反之则不成立。例如，下图中有两个局部极小，但只有其中之一是全局最小。显然，我们在参数寻优过程中是希望找到全局最小。

![全局最小与局部极小.png](https://github.com/Giyn/QG2020SummerTraining/blob/master/Pictures/BPNN/%E5%85%A8%E5%B1%80%E6%9C%80%E5%B0%8F%E4%B8%8E%E5%B1%80%E9%83%A8%E6%9E%81%E5%B0%8F.png?raw=true)

​		基于梯度的搜索是使用最为广泛的参数寻优方法。在此类方法中，我们从某些初始解出发，迭代寻找最优参数值。每次迭代中，先计算误差函数在当前点的梯度，然后根据梯度确定搜索方向。例如，由于负梯度方向是函数值下降最快的方向，因此梯度下降法就是沿着负梯度方向搜索最优解。若误差函数在当前点的梯度为零，则已达到局部极小，更新量将为零，这意味着参数的迭代更新将在此停止。显然，如果误差函数仅有一个局部极小，那么此时找到的局部极小就是全局最小；然而，如果误差函数具有多个局部极小，则不能保证找到的解是全局最小。对后一种情形，我们称参数寻优陷入了局部极小，这显然不是我们所希望的。

​		在现实任务中，人们常采用以下策略来试图“跳出”局部极小，从而进一步接近全局最小：

- **以多组不同参数值初始化多个神经网络，按标准方法训练后，取其中误差最小的解作为最终参数。**这相当于从多个不同的初始点开始搜索，这样就可能陷入不同的局部极小，从中进行选择有可能获得更接近全局最小的结果。
- **使用“模拟退火”(simulated annealing)技术。**模拟退火在每一步都以一定的概率接受比当前解更差的结果，从而有助于“跳出”局部极小。在每步迭代过程中，接受“次优解”的概率要随着时间的推移而逐渐降低，从而保证算法稳定。
- **使用随机梯度下降。**与标准梯度下降法精确计算梯度不同，随机梯度下降法在计算梯度时加入了随机因素。于是，即便陷入局部极小点，它计算出的梯度仍可能不为零，这样就有机会跳出局部极小继续搜索。

>但是也会造成“跳出”全局最小。

​		此外，遗传算法 (genetic algorithms) 也常用来训练神经网络以更好地逼近全局最小。需注意的是，上述用于跳出局部极小的技术大多是启发式，理论上尚缺乏保障。



### $BPNN$ 优缺点：

#### 优点：

- 具有实现任何复杂非线性映射的功能。这使得它特别适合于求解内部机制复杂的问题；
- 具有自学习能力；
- 具有一定的推广、概括能力；

#### 缺点：

- 学习速度很慢；
- 网络结构的选择一般只能由经验选定；
- 容易出现“过拟合”现象；



## 其他常见神经网络

### $RBF$ 网络

​		$RBF$ (Radial Basis Function，径向基函数) 网络是一种单隐层前馈神经网络，它使用径向基函数作为隐层神经元激活函数，而输出层则是对隐层神经元输出的线性组合。假定输入为 $d$ 维向量 $x$，输出为实值，则 $RBF$ 网络可表示为
$$
\varphi(x)=\sum^q_{i=1}w_i\rho(x,c_i)\,\,,\tag{18}
$$
其中 $q$ 为隐层神经元个数，$c_i$ 和 $w_i$ 分别是第 $i$ 个隐层神经元所对应的中心和权重，$\rho(x,c_i)$ 是径向基函数，这是某种沿径向对称的标量函数，通常定义为样本 $x$ 到数据中心 $c_i$ 之间欧氏距离的单调函数。常用的高斯径向基函数形如
$$
\rho(x,c_i)=e^{-\beta_i||x-c_i||^2}\,\,.\tag{19}
$$

>具有足够多隐层神经元的 $RBF$ 网络能以任意精度逼近任意连续函数。

​		通常采用两步过程来训练 $RBF$ 网络：第一步，确定神经元中心 $c_i$，常用的方式包括随机采样、聚类等；第二步，利用 $BP$ 算法等来确定参数 $w_i$ 和 $\beta_i$。



### $ART$ 网络

​		竞争型学习 (competitive learning) 是神经网络中一种常用的无监督学习策略，在使用该策略时，网络的输出神经元相互竞争，每一时刻仅有一个竞争获胜的神经元被激活，其他神经元的状态被抑制。这种机制亦称“胜者通吃”(winner-take-all)原则。
​		ART (Adaptive Resonance Theory，自适应谐振理论) 网络是竞争型学习的重要代表。该网络由比较层、识别层、识别阈值和重置模块构成。其中，比较层负责接收输入样本，并将其传递给识别层神经元。识别层每个神经元对应一个模式类，神经元数目可在训练过程中动态增长以增加新的模式类。

>模式类可认为是某类别的“子类"。

​		在接收到比较层的输入信号后，识别层神经元之间相互竞争以产生获胜神经元。**竞争的最简单方式是，计算输入向量与每个识别层神经元所对应的模式类的代表向量之间的距离，距离最小者胜。获胜神经元将向其他识别层神经元发送信号，抑制其激活。**若输入向量与获胜神经元所对应的代表向量之间的相似度大于识别阈值，则当前输入样本将被归为该代表向量所属类别，同时，网络连接权将会更新，使得以后在接收到相似输入样本时该模式类会计算出更大的相似度，从而使该获胜神经元有更大可能获胜；若相似度不大于识别阈值，则重置模块将在识别层增设一个新的神经元，其代表向量就设置为当前输入向量。

​		显然，识别阈值对 $ART$ 网络的性能有重要影响。当识别阈值较高时，输入样本将会被分成比较多、比较精细的模式类，而如果识别阈值较低，则会产生比较少、比较粗略的模式类。

​		$ART$ 比较好地缓解了竞争型学习中的“可塑性稳定性窘境” (stability-plasticity dilemma)，可塑性是指神经网络要有学习新知识的能力，而稳定性则是指神经网络在学习新知识时要保持对旧知识的记忆。这就使得 $ART$ 网络具有一个很重要的优点：可进行增量学习 (incremental learning) 或在线学习 (onlinelearning)。

>增量学习是指在学得模型后，再接收到训练样例时，仅需根据新样例对模型进行更新，不必重新训练整个模型，并且先前学得的有效信息不会被“冲掉”；
>
>在线学习是指每获得一个新样本就进行一次模型更新。显然，在线学习是增量学习的特例，而增量学习可视为“批模式” (batch-mode) 的在线学习。

​		早期的 $ART$ 网络只能处理布尔型输入数据，此后 $ART$ 发展成了一个算法族，包括能处理实值输入的 $ART2$ 网络、结合模糊处理的 $FuzzyART$ 网络，以及可进行监督学习的 $ARTMAP$ 网络等。



### $SOM$ 网络

​		$SOM$ (Self-Organizing Map，自组织映射) 网络是一种竞争学习型的无监督神经网络，它能将高维输入数据映射到低维空间 (通常为二维)，同时保持输入数据在高维空间的拓扑结构，即将高维空间中相似的样本点映射到网络输出层中的邻近神经元。

​		如下图所示，$SOM$ 网络中的输出层神经元以矩阵方式排列在二维空间中，每个神经元都拥有一个权向量，网络在接收输入向量后，将会确定输出层获胜神经元，它决定了该输入向量在低维空间中的位置。$SOM$ 的训练目标就是为每个输出层神经元找到合适的权向量，以达到保持拓扑结构的目的。

![SOM网络结构.png](https://github.com/Giyn/QG2020SummerTraining/blob/master/Pictures/BPNN/SOM%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png?raw=true)

​		$SOM$ 的训练过程很简单：在接收到一个训练样本后，每个输出层神经元会计算该样本与自身携带的权向量之间的距离，距离最近的神经元成为竞争获胜者，称为最佳匹配单元 (best matching unit)。然后，最佳匹配单元及其邻近神经元的权向量将被调整，以使得这些权向量与当前输入样本的距离缩小。这个过程不断迭代，直至收敛。



### 级联相关网络

​		一般的神经网络模型通常假定网络结构是事先固定的，训练的目的是利用训练样本来确定合适的连接权、阈值等参数。与此不同，结构自适应网络则将网络结构也当作学习的目标之一，并希望能在训练过程中找到最符合数据特点的网络结构。级联相关 (Cascade-Correlation) 网络是结构自适应网络的重要代表。

![级联相关网络的训练过程.新的隐结点加入时,红色连接权通过最大化新结点的输出与网络误差之间的相关性来进行训练.png](https://github.com/Giyn/QG2020SummerTraining/blob/master/Pictures/BPNN/%E7%BA%A7%E8%81%94%E7%9B%B8%E5%85%B3%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B.%E6%96%B0%E7%9A%84%E9%9A%90%E7%BB%93%E7%82%B9%E5%8A%A0%E5%85%A5%E6%97%B6,%E7%BA%A2%E8%89%B2%E8%BF%9E%E6%8E%A5%E6%9D%83%E9%80%9A%E8%BF%87%E6%9C%80%E5%A4%A7%E5%8C%96%E6%96%B0%E7%BB%93%E7%82%B9%E7%9A%84%E8%BE%93%E5%87%BA%E4%B8%8E%E7%BD%91%E7%BB%9C%E8%AF%AF%E5%B7%AE%E4%B9%8B%E9%97%B4%E7%9A%84%E7%9B%B8%E5%85%B3%E6%80%A7%E6%9D%A5%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83.png?raw=true)

​		级联相关网络有两个主要成分：“级联” 和“相关”。级联是指建立层次连接的层级结构。在开始训练时，网络只有输入层和输出层，处于最小拓扑结构；随着训练的进行，如上图所示，新的隐层神经元逐渐加入，从而创建起层级结构。当新的隐层神经元加入时，其输入端连接权值是冻结固定的。相关是指通过最大化新神经元的输出与网络误差之间的相关性 (correlation) 来训练相关的参数。
​		与一般的前馈神经网络相比，级联相关网络无需设置网络层数、隐层神经元数目，且训练速度较快，但其在数据较小时易陷入过拟合。



### $Elman$ 网络

​		与前馈神经网络不同，“ 递归神经网络” (recurrent neural networks) 允许网络中出现环形结构，从而可让一些神经元的输出反馈回来作为输入信号。这样的结构与信息反馈过程，使得网络在 t 时刻的输出状态不仅与 t 时刻的输入有关，还与 t-1 时刻的网络状态有关，从而能处理与时间有关的动态变化。
​		$Elman$ 网络是最常用的递归神经网络之一，其结构如下图所示，它的结构与多层前馈网络很相似，但隐层神经元的输出被反馈回来，与下一时刻输入层神经元提供的信号一起，作为隐层神经元在下一时刻的输入。隐层神经元通常采用 Sigmoid 激活函数，而网络的训练则常通过推广的 $BP$ 算法进行。

![Elman网络结构.png](https://github.com/Giyn/QG2020SummerTraining/blob/master/Pictures/BPNN/Elman%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png?raw=true)



### $Boltzmann$ 机

​		神经网络中有一类模型是为网络状态定义一个“能量”(energy)，能量最小化时网络达到理想状态，而网络的训练就是在最小化这个能量函数。$Boltzmann$ 机就是一种“基于能量的模型”(energy-basedmodel)，常见结构如下图 (a) 所示，其神经元分为两层：显层与隐层。显层用于表示数据的输入与输出，隐层则被理解为数据的内在表达。$Boltzmann$ 机中的神经元都是布尔型的，即只能取 0、1 两种状态，状态 1 表示激活，状态 0 表示抑制。令向量 $s∈\{0,1\}^n$表示 $n$ 个神经元的状态，$w_{ij}$表示神经元 $i$ 与 $j$ 之间的连接权，$\theta_i$ 表示神经元 $i$ 的阈值，则状态向量 $s$ 所对应的 $Boltzmann$ 机能量定义为
$$
E(s)=-\sum^{n-1}_{i=1}\sum^n_{j=i+1}w_{ij}s_is_j-\sum^n_{i=1}\theta_is_i\,\,.\tag{20}
$$

> $Boltzmann$ 机是一种递归神经网络。

![Boltzmann机与受限Boltzmann机.png](https://github.com/Giyn/QG2020SummerTraining/blob/master/Pictures/BPNN/Boltzmann%E6%9C%BA%E4%B8%8E%E5%8F%97%E9%99%90Boltzmann%E6%9C%BA.png?raw=true)

​		若网络中的神经元以任意不依赖于输入值的顺序进行更新，则网络最终将达到 $Boltzmann$ 分布，此时状态向量 $s$ 出现的概率将仅由其能量与所有可能状态向量的能量确定：
$$
P(s)=\frac{e^{-E(s)}}{\sum_te^{-E(t)}}\,\,.\tag{21}
$$

>$Boltzmann$ 分布亦称"平衡态”(equilibrium)或“平稳分布”(station-ary distribution)。

​		$Boltzmann$ 机的训练过程就是将每个训练样本视为一个状态向量，使其出现的概率尽可能大。标准的 $Boltzmann$ 机是一个全连接图，训练网络的复杂度很高，这使其难以用于解决现实任务。现实中常采用受限 $Boltzmann$ 机(Restricted Boltzmann Machine，简称 $RBM$ )。如上图 (b) 所示，受限 $Boltzmann$ 机仅保留显层与隐层之间的连接，从而将 $Boltzmann$ 机结构由完全图简化为二部图。
​		受限 $Boltzmann$ 机常用“ 对比散度”(Contrastive Divergence，简称 $CD$ )算法来进行训练，假定网络中有 $d$ 个显层神经元和 $q$ 个隐层神经元，令 $v$ 和 $h$ 分别表示显层与隐层的状态向量，则由于同一层内不存在连接，有
$$
P(v\mid h)=	\prod^d_{i=1}P(v_i\mid h)\,\,,\tag{22}
$$

$$
P(h\mid v)=\prod^q_{j=1}P(h_j\mid v)\,\,.\tag{23}
$$

​		$CD$ 算法对每个训练样本 $v$，先根据式 (23) 计算出隐层神经元状态的概率分布，然后根据这个概率分布采样得到 $h$；此后，类似地根据式 (22) 从 $h$ 产生 $v'$，再从 $v'$ 产生 $h'$；连接权的更新公式为
$$
\Delta w=\eta(vh^T-v'h'^T)\,\,.\tag{24}
$$

---

Reference：《机器学习》